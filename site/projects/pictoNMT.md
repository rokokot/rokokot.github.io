---
title: "PictoNMT: Multimodal Picto-to-Text Machine Translation"
dates: 2025 - Present
collaborators: Vincent Vandeghinste
---

## PictoNMT: Multimodal Picto-to-Text Machine Translation

## Project Overview

This project aims to develop a novel multimodal translation system that converts pictographic communication (used in Augmentative and Alternative Communication) into natural language text. By leveraging deep learning techniques, we're creating more fluid communication pathways for users of pictographic communication systems.

## Key Contributions

### Neural Translation Architecture

We've designed a specialized neural architecture that handles both visual and semantic aspects of pictographic symbols, enabling context-aware translation to text.

### Multimodal Alignment

Our approach solves the alignment problem between pictographic symbols and natural language grammatical structures, accounting for the fundamentally different nature of these communication forms.

### User-Adaptive Systems

The system incorporates user preferences and communication patterns, allowing for personalized translations that match individual communication styles.

## Summary of Results

Our preliminary results show a 35% improvement in translation fluency compared to rule-based approaches, with particularly strong performance in handling contextual meaning.

## Applications

We're exploring applications in several domains:

### Assistive Technology

Integration with existing AAC devices to provide more natural-sounding output for users of pictographic communication systems.

### Language Learning

Supporting second language acquisition by providing pictographic-to-text translation for learners at early stages of language development.

### Cross-modal Communication

Bridging communication between visual and textual information processing systems in multimodal interfaces.
